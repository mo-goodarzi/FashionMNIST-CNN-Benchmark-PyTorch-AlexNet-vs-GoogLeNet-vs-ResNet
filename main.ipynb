{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b268304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms.v2 as T\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93074b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d108228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_loader, n_epochs,device):\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        mean_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {mean_loss:.4f}\")\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader, metric_fn, aggregate_fn=torch.mean):\n",
    "    model.eval()\n",
    "    metrics = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch)\n",
    "            metric = metric_fn(y_pred, y_batch)\n",
    "            metrics.append(metric.cpu())\n",
    "    return aggregate_fn(torch.stack(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "846ac055",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:02<00:00, 10.6MB/s]\n",
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 205kB/s]\n",
      "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.82MB/s]\n",
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 27.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "toTensor = T.Compose([T.ToImage(), T.ToDtype(torch.float32, scale=True)])\n",
    "\n",
    "train_and_valid_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"datasets\", train=True, transform=toTensor, download=True\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"datasets\", train=False, transform=toTensor, download=True\n",
    ")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_data, valid_data = torch.utils.data.random_split(\n",
    "    train_and_valid_data, [55_000, 5_000]\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=32)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "491291e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_classes=1000):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=out_channels, out_channels=192, kernel_size=5, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=192, out_channels=384, kernel_size=3, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.AdaptiveAvgPool2d((6, 6)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=256*6*6, out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=4096, out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=4096, out_features=num_classes),\n",
    "            # nn.Softmax(dim=1)\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0302a8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ebd5d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].shape, a[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "399c051b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.6037\n",
      "Epoch 2/20, Loss: 0.3792\n",
      "Epoch 3/20, Loss: 0.3403\n",
      "Epoch 4/20, Loss: 0.3172\n",
      "Epoch 5/20, Loss: 0.3004\n",
      "Epoch 6/20, Loss: 0.2854\n",
      "Epoch 7/20, Loss: 0.2814\n",
      "Epoch 8/20, Loss: 0.2732\n",
      "Epoch 9/20, Loss: 0.2720\n",
      "Epoch 10/20, Loss: 0.2547\n",
      "Epoch 11/20, Loss: 0.2518\n",
      "Epoch 12/20, Loss: 0.2533\n",
      "Epoch 13/20, Loss: 0.2588\n",
      "Epoch 14/20, Loss: 0.2435\n",
      "Epoch 15/20, Loss: 0.2585\n",
      "Epoch 16/20, Loss: 0.2477\n",
      "Epoch 17/20, Loss: 0.2345\n",
      "Epoch 18/20, Loss: 0.2438\n",
      "Epoch 19/20, Loss: 0.2325\n",
      "Epoch 20/20, Loss: 0.2336\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "model = AlexNet(in_channels=1, out_channels=96, num_classes=10).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train(model, optimizer, criterion, train_loader, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "997b0fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9294\n",
      "Validation Accuracy: 0.9015\n",
      "Test Accuracy: 0.9004\n"
     ]
    }
   ],
   "source": [
    "import torchmetrics\n",
    "\n",
    "accuracy_fn = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "\n",
    "print(f\"Training Accuracy: {evaluate(model, train_loader, accuracy_fn):.4f}\")\n",
    "print(f\"Validation Accuracy: {evaluate(model, valid_loader, accuracy_fn):.4f}\")\n",
    "print(f\"Test Accuracy: {evaluate(model, test_loader, accuracy_fn):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a783d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2aba501",
   "metadata": {},
   "source": [
    "# GoogLeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b307c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.most_right = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.right = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=5, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.most_left = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        most_right = self.most_right(x)\n",
    "        right = self.right(x)\n",
    "        left = self.left(x)\n",
    "        most_left = self.most_left(x)\n",
    "        return torch.cat([most_right, right, left, most_left], dim=1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f8a4d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_classes=1000):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=7, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Conv2d(in_channels=out_channels, out_channels=192, kernel_size=1, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=192, out_channels=192, kernel_size=3, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            Inception(in_channels=192, out_channels=64),\n",
    "            Inception(in_channels=256, out_channels=120),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "\n",
    "            Inception(in_channels=480, out_channels=128),  # -> (B, 512, 3, 3)\n",
    "            Inception(in_channels=512, out_channels=128),  # -> (B, 512, 3, 3)\n",
    "            Inception(in_channels=512, out_channels=208),  # -> (B, 832, 3, 3)\n",
    "\n",
    "\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),  # -> (B, C, 1, 1)\n",
    "            nn.Flatten(),                  # -> (B, C)\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(832, num_classes)    # logits (NO softmax)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2aff91c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(train_loader))\n",
    "sample[0].shape, sample[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee93fa6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = GoogLeNet(in_channels=1, out_channels=96, num_classes=10).to(device)\n",
    "example(sample[0].to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa40ef3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = GoogLeNet(in_channels=1, out_channels=96, num_classes=10).to(device)\n",
    "example(sample[0].to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c16c0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.5505\n",
      "Epoch 2/20, Loss: 0.3456\n",
      "Epoch 3/20, Loss: 0.3001\n",
      "Epoch 4/20, Loss: 0.2680\n",
      "Epoch 5/20, Loss: 0.2502\n",
      "Epoch 6/20, Loss: 0.2354\n",
      "Epoch 7/20, Loss: 0.2227\n",
      "Epoch 8/20, Loss: 0.2051\n",
      "Epoch 9/20, Loss: 0.1985\n",
      "Epoch 10/20, Loss: 0.1913\n",
      "Epoch 11/20, Loss: 0.1777\n",
      "Epoch 12/20, Loss: 0.1683\n",
      "Epoch 13/20, Loss: 0.1631\n",
      "Epoch 14/20, Loss: 0.1549\n",
      "Epoch 15/20, Loss: 0.1442\n",
      "Epoch 16/20, Loss: 0.1460\n",
      "Epoch 17/20, Loss: 0.1316\n",
      "Epoch 18/20, Loss: 0.1333\n",
      "Epoch 19/20, Loss: 0.1250\n",
      "Epoch 20/20, Loss: 0.1214\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "model = GoogLeNet(in_channels=1, out_channels=96, num_classes=10).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train(model, optimizer, criterion, train_loader, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb99b6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9616\n",
      "Validation Accuracy: 0.9122\n",
      "Test Accuracy: 0.9144\n"
     ]
    }
   ],
   "source": [
    "import torchmetrics\n",
    "\n",
    "accuracy_fn = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "\n",
    "print(f\"Training Accuracy: {evaluate(model, train_loader, accuracy_fn):.4f}\")\n",
    "print(f\"Validation Accuracy: {evaluate(model, valid_loader, accuracy_fn):.4f}\")\n",
    "print(f\"Test Accuracy: {evaluate(model, test_loader, accuracy_fn):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b532c87",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40a240e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class residual_unit(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, stride=1):\n",
    "#         super().__init__()\n",
    "#         self.DefaultConv2d = partial(\n",
    "#             nn.Conv2d, kernel_size=3, stride=stride, padding=1, bias=False\n",
    "#         )\n",
    "        \n",
    "#         self.main_layers = nn.Sequential(\n",
    "#             self.DefaultConv2d(in_channels, out_channels, stride=stride),\n",
    "#             nn.BatchNorm2d(out_channels),\n",
    "#             nn.ReLU(),\n",
    "#             self.DefaultConv2d(out_channels, out_channels),\n",
    "#             nn.BatchNorm2d(out_channels)\n",
    "#         )\n",
    "\n",
    "#         if stride > 1:\n",
    "#             self.skip_connection = nn.Sequential(\n",
    "#                 self.DefaultConv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0),\n",
    "#                 nn.BatchNorm2d(out_channels)\n",
    "#             )\n",
    "#         else:\n",
    "#             self.skip_connection = nn.Identity()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return F.relu(self.main_layers(x) + self.skip_connection(x))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class residual_unit(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Only fix kernel_size/padding/bias here (NOT stride)\n",
    "        DefaultConv3x3 = partial(nn.Conv2d, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "        self.main_layers = nn.Sequential(\n",
    "            DefaultConv3x3(in_channels, out_channels, stride=stride),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            DefaultConv3x3(out_channels, out_channels, stride=1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "        # Projection shortcut if shape changes (stride or channels)\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.skip_connection = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.main_layers(x)\n",
    "        skip = self.skip_connection(x)\n",
    "        return F.relu(out + skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c51aec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layers = [\n",
    "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "\n",
    "        ]\n",
    "\n",
    "        prev_filters = 64\n",
    "\n",
    "        for filters in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:\n",
    "            layers.append(residual_unit(prev_filters, filters, stride=1 if filters == prev_filters else 2))\n",
    "            prev_filters = filters\n",
    "\n",
    "        layers+=[\n",
    "            nn.AdaptiveAvgPool2d(output_size=1),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(10)\n",
    "        ]\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2baa9e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3212b821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smaple = next(iter(train_loader))\n",
    "model(smaple[0].to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea878fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resnet(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): residual_unit(\n",
       "      (main_layers): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (5): residual_unit(\n",
       "      (main_layers): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (6): residual_unit(\n",
       "      (main_layers): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (7): residual_unit(\n",
       "      (main_layers): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_connection): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): residual_unit(\n",
       "      (main_layers): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (9): residual_unit(\n",
       "      (main_layers): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (10): residual_unit(\n",
       "      (main_layers): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (11): residual_unit(\n",
       "      (main_layers): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_connection): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): residual_unit(\n",
       "      (main_layers): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (13): residual_unit(\n",
       "      (main_layers): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (14): residual_unit(\n",
       "      (main_layers): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (15): residual_unit(\n",
       "      (main_layers): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (16): residual_unit(\n",
       "      (main_layers): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (17): residual_unit(\n",
       "      (main_layers): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_connection): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): residual_unit(\n",
       "      (main_layers): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (19): residual_unit(\n",
       "      (main_layers): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (20): AdaptiveAvgPool2d(output_size=1)\n",
       "    (21): Flatten(start_dim=1, end_dim=-1)\n",
       "    (22): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f4714a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f6284b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.5140\n",
      "Epoch 2/20, Loss: 0.3555\n",
      "Epoch 3/20, Loss: 0.3088\n",
      "Epoch 4/20, Loss: 0.2922\n",
      "Epoch 5/20, Loss: 0.2580\n",
      "Epoch 6/20, Loss: 0.2406\n",
      "Epoch 7/20, Loss: 0.2195\n",
      "Epoch 8/20, Loss: 0.2105\n",
      "Epoch 9/20, Loss: 0.1856\n",
      "Epoch 10/20, Loss: 0.1696\n",
      "Epoch 11/20, Loss: 0.1549\n",
      "Epoch 12/20, Loss: 0.1460\n",
      "Epoch 13/20, Loss: 0.1307\n",
      "Epoch 14/20, Loss: 0.1209\n",
      "Epoch 15/20, Loss: 0.1092\n",
      "Epoch 16/20, Loss: 0.0995\n",
      "Epoch 17/20, Loss: 0.0954\n",
      "Epoch 18/20, Loss: 0.0827\n",
      "Epoch 19/20, Loss: 0.0780\n",
      "Epoch 20/20, Loss: 0.0740\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, criterion, train_loader, n_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7093311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (26.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.10.0+cu128)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
      "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.24.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.6.0)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch>=2.0.0->torchmetrics) (1.3.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
      "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
      "Installing collected packages: lightning-utilities, torchmetrics\n",
      "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7568b2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9843\n",
      "Validation Accuracy: 0.9170\n",
      "Test Accuracy: 0.9122\n"
     ]
    }
   ],
   "source": [
    "import torchmetrics\n",
    "\n",
    "accuracy_fn = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "\n",
    "print(f\"Training Accuracy: {evaluate(model, train_loader, accuracy_fn):.4f}\")\n",
    "print(f\"Validation Accuracy: {evaluate(model, valid_loader, accuracy_fn):.4f}\")\n",
    "print(f\"Test Accuracy: {evaluate(model, test_loader, accuracy_fn):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
